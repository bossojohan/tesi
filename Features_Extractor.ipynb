{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 100, 2048)         0         \n",
      "_________________________________________________________________\n",
      "net_vlad_3 (NetVLAD)         (None, 72)                9699392   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 219       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 9,699,615\n",
      "Trainable params: 9,699,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If your data is in the form of symbolic tensors, you should specify the `steps` argument (instead of the `batch_size` argument, because symbolic tensors are expected to produce batches of input data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-29a5211795a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodello\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bossoenv/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/bossoenv/lib/python3.4/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    243\u001b[0m                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                                     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                                     steps_name='steps')\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bossoenv/lib/python3.4/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_num_samples\u001b[0;34m(ins, batch_size, steps, steps_name)\u001b[0m\n\u001b[1;32m    567\u001b[0m             raise ValueError(\n\u001b[1;32m    568\u001b[0m                 \u001b[0;34m'If your data is in the form of symbolic tensors, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m                 \u001b[0;34m'you should specify the `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msteps_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'` argument '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m                 \u001b[0;34m'(instead of the `batch_size` argument, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0;34m'because symbolic tensors are expected to produce '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If your data is in the form of symbolic tensors, you should specify the `steps` argument (instead of the `batch_size` argument, because symbolic tensors are expected to produce batches of input data)."
     ]
    }
   ],
   "source": [
    "import os.path, csv, glob\n",
    "import import_ipynb\n",
    "from keras.models import Input\n",
    "from keras.preprocessing import image\n",
    "from Extractor import Extractor\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import loupe_keras as lpk\n",
    "from Model import MyNet\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "def getFrames(sample):\n",
    "        root_path = 'SoccerNet/SoccerNet-code/data/data'  \n",
    "        code_action = sample[0][:3]\n",
    "        game_time = sample[0][3]+'_'+sample[0][6:11]   \n",
    "        game_code = sample[2]        \n",
    "        name_file = code_action+game_time\n",
    "        specific_path =os.path.join(code_action,game_code,game_time)\n",
    "        path = os.path.join(root_path, specific_path)         \n",
    "        images = sorted(glob.glob(os.path.join(path, name_file+'*jpg')))         \n",
    "        return images\n",
    "    \n",
    "\n",
    "    \n",
    "def rescaleList(input_list, size):        \n",
    "        assert len(input_list) >= size\n",
    "        skip = len(input_list) // size\n",
    "        output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
    "        return output[:size]\n",
    "    \n",
    "sequence_length = 100 \n",
    "exmodel= Extractor()\n",
    "trainer = MyNet()\n",
    "with open('data_file.csv','r') as datafile:\n",
    "    reader = csv.reader(datafile, delimiter=',')\n",
    "    globalList=[]\n",
    "    for row in reader:\n",
    "        frames = getFrames(row)        \n",
    "        frames = rescaleList(frames, sequence_length)\n",
    "        sequence =np.empty((0,2048), dtype=object)\n",
    "        for image in frames:            \n",
    "            features= exmodel.extract(image) #restituisce un [(2048)]\n",
    "            features = tf.expand_dims(features, axis=0) \n",
    "            sequence = tf.concat( (sequence, features), axis=0)\n",
    "        trainer.modello.predict(sequence)\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectname",
   "language": "python",
   "name": "projectname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
